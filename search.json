[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "As an individual or in a team pick a topic and\n\ncreate a (cleanish) dataset\nchoose an appropriate analysis\ninterpret results\npublish your analysis and findings\nCreate a video highlighting your work\n\nMore information will be coming as we get closer to the start of the project work."
  },
  {
    "objectID": "project/screencast-checklist.html",
    "href": "project/screencast-checklist.html",
    "title": "Screencast Checklist",
    "section": "",
    "text": "Screencast uploaded to YouTube/YuJa\n\nIf on YouTube, your screencast should be set so that anyone with the link can view the video.\n\nApproximate time index provided for each of the 4 techniques you’re demonstrating (examples) provided\n\nin the README of your github repository\nin the description of your video (if on YouTube)\n\nCommented code for your screencast uploaded to the github repository"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 471: Analysis of Messy Data",
    "section": "",
    "text": "Course Materials\nDates shown are due dates (for assignments and exams) and dates on which material was presented (for slides).\n\n\n\n\n\n\nModule 0: Setting up the work environment\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nType\n\n\n\n \n\n\n\n\n\n\n\n\nAug 26, 2025\n\n\nAbout Stat 471\n\n\nslides\n\n\n\n\n\n\n\n\n\nAug 26, 2025\n\n\nR, RStudio, git\n\n\nslides\n\n\n\n\n\n\n\n\n\nAug 28, 2025\n\n\nHomework 0 Setup A: Git and Github\n\n\nHomework\n\n\n\n\n\n\n\n\n\nSep 2, 2025\n\n\nHomework 0 Setup B: Connecting RStudio and Git\n\n\nHomework\n\n\n\n\n\n\n\n\n\nSep 4, 2025\n\n\nHomework 1: Reproducibility\n\n\nHomework\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nModule 1: Tidy forms of data\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nType\n\n\n\n \n\n\n\n\n\n\n\n\nAug 28, 2025\n\n\nWhat is “Messy Data”?\n\n\nslides\n\n\n\n\n\n\n\n\n\nSep 2, 2025\n\n\nNormal Forms of data\n\n\nslides\n\n\n\n\n\n\n\n\n\nSep 2, 2025\n\n\nNormalizing Data\n\n\nslides\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nModule 2: Data Cleaning\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\nDate\nTitle\nType\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nModule 3: Working with Missing Values\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\nDate\nTitle\nType\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nModule 4: Record Linkage: joining data from different sources\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\nDate\nTitle\nType\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nModule 5: Working with large data\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\nDate\nTitle\nType\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials-2025/Module 1 - Tidy Forms of Data/03-normalizing-data.html",
    "href": "materials-2025/Module 1 - Tidy Forms of Data/03-normalizing-data.html",
    "title": "Normalizing Data",
    "section": "",
    "text": "Normalization strategies\n\nCheck whether the data set has a (primary) key\n\n\n\nIdentify candidate keys\n\nAre there duplicated rows?\n\n\n# Check uniqueness\n!any(duplicated(&lt;data set&gt;))\n\nError in parse(text = input): &lt;text&gt;:2:17: unexpected '&lt;'\n1: # Check uniqueness\n2: !any(duplicated(&lt;\n                   ^\n\n\nIf there are duplicates, there is either no key or some rows were accidentally duplicated - count what proportion of lines is duplicated\n\nKeys have to uniquely identify a row\n\nIf variables cand1, cand2 are a key candidate, check whether they uniquely identify rows:\n\n# Check for unique combinations\n&lt;data set&gt; %&gt;% \n  count(cand) %&gt;% \n  filter(n &gt; 1)\n\nError in parse(text = input): &lt;text&gt;:2:1: unexpected '&lt;'\n1: # Check for unique combinations\n2: &lt;\n   ^\n\n\n\n\nHow much normalization?\nRule of thumb: Normalize to eliminate anomalies, denormalize for performance. Find the sweet spot for your use case."
  },
  {
    "objectID": "materials-2025/leftovers.html",
    "href": "materials-2025/leftovers.html",
    "title": "Leftovers",
    "section": "",
    "text": "“Analysis of messy data” refers to the statistical methods and techniques specifically designed to handle data that violates the clean assumptions of standard statistical methods. This is different from “messy data analysis” (the process) - this is about the analytical techniques themselves."
  },
  {
    "objectID": "materials-2025/leftovers.html#what-makes-data-messy-statistically",
    "href": "materials-2025/leftovers.html#what-makes-data-messy-statistically",
    "title": "Leftovers",
    "section": "What Makes Data “Messy” Statistically",
    "text": "What Makes Data “Messy” Statistically\n\nCommon Messy Data Problems:\n\nMissing values (not at random)\nOutliers and anomalies\n\nNon-normal distributions"
  },
  {
    "objectID": "materials-2025/leftovers.html#best-practices-for-messy-data-analysis",
    "href": "materials-2025/leftovers.html#best-practices-for-messy-data-analysis",
    "title": "Leftovers",
    "section": "Best Practices for Messy Data Analysis",
    "text": "Best Practices for Messy Data Analysis\n\n1. Understand Your Messiness\n\nWhy is the data messy?\nIs it measurement error, missing by design, or data quality issues?\nDifferent causes require different solutions\n\n\n\n2. Don’t Rush to Clean\n\nSometimes the “mess” contains important information\nMissing patterns might be informative\nOutliers might be your most interesting observations\n\n\n\n3. Sensitivity Analysis\n\nTry multiple approaches\nSee if conclusions are robust across methods\nDocument what changes and what doesn’t\n\n\n\n4. Model the Mess\n\nInstead of cleaning first, model the messiness directly\nInclude missingness indicators as variables\nUse hierarchical models for complex structure\n\nWhat is messy data analysis\n“Messy data analysis” refers to the realistic, iterative, and often chaotic process of working with real-world data - as opposed to the clean, linear process often taught in textbooks."
  },
  {
    "objectID": "materials-2025/leftovers.html#what-makes-data-analysis-messy",
    "href": "materials-2025/leftovers.html#what-makes-data-analysis-messy",
    "title": "Leftovers",
    "section": "What Makes Data Analysis “Messy”",
    "text": "What Makes Data Analysis “Messy”\n\n1. Non-linear Process\n\nAnalysis rarely goes: collect ??? clean ??? analyze ??? report\nInstead: analyze ??? discover problems ??? go back ??? re-clean ??? re-analyze ??? repeat\nConstant backtracking and revision\n\n\n\n3. Unexpected Discoveries\n\nYour hypothesis was wrong\nThe “smoking gun” variable is actually data entry errors\nThe interesting pattern disappears when you fix a bug"
  },
  {
    "objectID": "materials-2025/leftovers.html#characteristics-of-messy-analysis",
    "href": "materials-2025/leftovers.html#characteristics-of-messy-analysis",
    "title": "Leftovers",
    "section": "Characteristics of Messy Analysis",
    "text": "Characteristics of Messy Analysis\n\nExploratory & Iterative\n\nStart without knowing exactly what you’re looking for\nFollow interesting leads that emerge\nDead ends and false starts are normal\n\n\n\nProblem-Driven\n\nQuestions evolve as you learn more about the data\nOriginal research question often changes completely\nAnalysis shaped by what’s actually possible with your data\n\n\n\nTool-Switching\n\nExcel for quick looks\nR/Python for analysis\n\nBack to Excel to check something\nMaybe some SQL, maybe some manual inspection\n\n\n\nDocumentation Challenges\n\nHard to document a non-linear process\nYour final clean code doesn’t show the messy exploration\nReproducibility becomes complex"
  },
  {
    "objectID": "materials-2025/leftovers.html#example-of-messy-analysis-flow",
    "href": "materials-2025/leftovers.html#example-of-messy-analysis-flow",
    "title": "Leftovers",
    "section": "Example of Messy Analysis Flow",
    "text": "Example of Messy Analysis Flow\n1. Load data ??? discover 50% missing values\n2. Investigate missingness ??? find it's not random\n3. Research data collection ??? learn about system change in 2019\n4. Split analysis by time period ??? find different patterns\n5. Discover outliers ??? some are errors, some are real\n6. Clean errors ??? realize you need domain expertise\n7. Consult with subject matter expert ??? learn your assumptions were wrong\n8. Start over with new understanding..."
  },
  {
    "objectID": "materials-2025/leftovers.html#messy-vs.-tidy",
    "href": "materials-2025/leftovers.html#messy-vs.-tidy",
    "title": "Leftovers",
    "section": "Messy vs. Tidy",
    "text": "Messy vs. Tidy\nHadley Wickham’s “Tidy Data” principles help organize the technical structure, but even with tidy data, the analysis process remains messy:\n\nTidy data: Structured format for easier manipulation\nMessy analysis: The human process of discovery and iteration"
  },
  {
    "objectID": "materials-2025/leftovers.html#embracing-the-mess",
    "href": "materials-2025/leftovers.html#embracing-the-mess",
    "title": "Leftovers",
    "section": "Embracing the Mess",
    "text": "Embracing the Mess\n\nGood Practices:\n\nKeep detailed lab notebooks/logs\nVersion control your code and data\nDocument dead ends (save future you time)\nExpect to throw away lots of work\nSeparate exploration from final analysis scripts\n\n\n\nTools for Messy Work:\n\nJupyter notebooks for exploration\nR Markdown for iterative analysis\nGit for tracking changes\nInformal plots and quick summaries\nCollaborative tools for team messiness"
  },
  {
    "objectID": "materials-2025/leftovers.html#why-this-matters",
    "href": "materials-2025/leftovers.html#why-this-matters",
    "title": "Leftovers",
    "section": "Why This Matters",
    "text": "Why This Matters\nUnderstanding that analysis is messy helps you: - Set realistic expectations for timelines - Budget time for exploration and dead ends - Communicate better with stakeholders about process - Feel normal when your analysis doesn’t go smoothly - Design better workflows that accommodate messiness\nBottom line: Real data analysis is messy, iterative, and full of surprises. The goal isn’t to eliminate the mess, but to manage it productively!\n“Messy data” refers to real-world datasets that don’t conform to the clean, structured format that statistical methods and analysis tools expect. It’s data that requires significant cleaning and preprocessing before analysis."
  },
  {
    "objectID": "materials-2025/leftovers.html#characteristics-of-messy-data",
    "href": "materials-2025/leftovers.html#characteristics-of-messy-data",
    "title": "Leftovers",
    "section": "Characteristics of Messy Data",
    "text": "Characteristics of Messy Data\n\n1. Structural Issues\n\nMultiple tables/sheets that should be combined\nVariables stored in rows instead of columns (or vice versa)\nMultiple variables crammed into one column\nHeaders and data mixed together\n\nExample:\nMessy format:\n┌─────────────────────────────────┐\n│        Sales Data 2023          │\n├─────────────────────────────────┤\n│ Q1: Jan=100, Feb=150, Mar=120   │\n│ Q2: Apr=200, May=180, Jun=220   │\n│ Total: 970                      │\n└─────────────────────────────────┘\n\nShould be:\n┌───────┬─────┬─────────┐\n│ Month │ Qtr │ Sales   │\n├───────┼─────┼─────────┤\n│ Jan   │ Q1  │ 100     │\n│ Feb   │ Q1  │ 150     │\n│ Mar   │ Q1  │ 120     │\n└───────┴─────┴─────────┘\n\n\n2. Data Quality Problems\n\nMissing values (blanks, “N/A”, “NULL”, -999, etc.)\nInconsistent formats (dates, currencies, addresses)\nTypos and spelling variations (“New York”, “NY”, “new york”)\nDuplicate records\nOutliers and impossible values (age = 150, negative prices)\n\n\n\n3. Encoding Issues\n\nDifferent data types in same column (numbers stored as text)\nCharacter encoding problems (ñ becomes Ã±)\nMixed units (some measurements in feet, others in meters)\nInconsistent categories (“Male/Female” vs “M/F” vs “1/0”)"
  },
  {
    "objectID": "materials-2025/leftovers.html#common-sources-of-messy-data",
    "href": "materials-2025/leftovers.html#common-sources-of-messy-data",
    "title": "Leftovers",
    "section": "Common Sources of Messy Data",
    "text": "Common Sources of Messy Data\n\nHuman Data Entry\nExpected:     Actual reality:\n┌──────┬────┐  ┌──────┬────────────┐\n│ Name │Age │  │ Name │ Age        │\n├──────┼────┤  ├──────┼────────────┤\n│ John │ 25 │  │ John │ 25         │\n│ Mary │ 30 │  │ mary │ thirty     │\n│ Bob  │ 22 │  │ Bob  │ 22 years   │\n└──────┴────┘  │      │ old        │\n               │ Rob  │ #N/A       │\n               └──────┴────────────┘\n\n\nSystem Integration\n\nData from multiple systems with different schemas\nLegacy systems with outdated formats\nAPIs that change structure over time\n\n\n\nExcel/Spreadsheet “Features”\n\nMerged cells\nFormulas mixed with data\n\nMultiple datasets in one sheet\nFormatting used to convey meaning\n\n\n\nWeb Scraping\n\nHTML tags mixed with content\nInconsistent page structures\nDynamic content that changes"
  },
  {
    "objectID": "materials-2025/leftovers.html#examples-of-messy-data",
    "href": "materials-2025/leftovers.html#examples-of-messy-data",
    "title": "Leftovers",
    "section": "Examples of Messy Data",
    "text": "Examples of Messy Data\n\nWide Format (Should be Long)\nMessy:\n┌─────────┬─────┬─────┬─────┬─────┐\n│ Country │2019 │2020 │2021 │2022 │\n├─────────┼─────┼─────┼─────┼─────┤\n│ USA     │ 100 │ 105 │ 103 │ 108 │\n│ Canada  │  80 │  82 │  79 │  85 │\n└─────────┴─────┴─────┴─────┴─────┘\n\nTidy:\n┌─────────┬──────┬───────┐\n│ Country │ Year │ Value │\n├─────────┼──────┼───────┤\n│ USA     │ 2019 │ 100   │\n│ USA     │ 2020 │ 105   │\n│ Canada  │ 2019 │  80   │\n└─────────┴──────┴───────┘\n\n\nMultiple Variables in One Column\nMessy:\n┌─────────────────────┐\n│ Name_Age_City       │\n├─────────────────────┤\n│ John_25_Boston      │\n│ Mary_30_Seattle     │\n└─────────────────────┘\n\nShould be:\n┌──────┬─────┬─────────┐\n│ Name │ Age │ City    │\n├──────┼─────┼─────────┤\n│ John │  25 │ Boston  │\n│ Mary │  30 │ Seattle │\n└──────┴─────┴─────────┘\n\n\nInconsistent Missing Value Codes\n┌──────┬─────┬────────┐\n│ Name │ Age │ Income │\n├──────┼─────┼────────┤\n│ John │  25 │ 50000  │\n│ Mary │ N/A │ -999   │\n│ Bob  │  30 │ NULL   │\n│ Sue  │   0 │        │\n└──────┴─────┴────────┘"
  },
  {
    "objectID": "materials-2025/leftovers.html#the-messy-vs-tidy-spectrum",
    "href": "materials-2025/leftovers.html#the-messy-vs-tidy-spectrum",
    "title": "Leftovers",
    "section": "The Messy vs Tidy Spectrum",
    "text": "The Messy vs Tidy Spectrum\nExtremely Messy: - PDF reports with embedded tables - Handwritten forms scanned as images - Audio/video that needs transcription\nModerately Messy: - Excel files with formatting and merged cells - CSVs with inconsistent column names - Databases with poor normalization\nSlightly Messy: - Clean structure but some missing values - Consistent format but needs type conversion - Good data with a few outliers\nTidy: - Each variable in its own column - Each observation in its own row - Each cell contains a single value - Consistent missing value handling"
  },
  {
    "objectID": "materials-2025/leftovers.html#tools-for-handling-messy-data",
    "href": "materials-2025/leftovers.html#tools-for-handling-messy-data",
    "title": "Leftovers",
    "section": "Tools for Handling Messy Data",
    "text": "Tools for Handling Messy Data\n\nR\nlibrary(tidyverse)  # dplyr, tidyr, stringr\nlibrary(janitor)    # clean_names(), get_dupes()\nlibrary(readxl)     # Excel files\nlibrary(VIM)        # Missing data visualization\nlibrary(OpenRefine) # GUI data cleaning\n\n\nPython\nimport pandas as pd\nimport numpy as np\nimport re  # Regular expressions\nfrom fuzzywuzzy import fuzz  # String matching\nimport missingno as msno  # Missing data viz\n\n\nSpecialized Tools\n\nOpenRefine: Interactive data cleaning\nTrifacta/Alteryx: Commercial data prep tools\nExcel Power Query: Built-in Excel cleaning tools"
  },
  {
    "objectID": "materials-2025/leftovers.html#why-messy-data-matters",
    "href": "materials-2025/leftovers.html#why-messy-data-matters",
    "title": "Leftovers",
    "section": "Why Messy Data Matters",
    "text": "Why Messy Data Matters\n\nReality Check\n\n80% of data science is data cleaning\nReal data is almost always messy\nTextbook examples don’t prepare you for reality\n\n\n\nBusiness Impact\n\nBad data leads to bad decisions\nCleaning takes time and resources\nAutomation can help but isn’t always possible\n\n\n\nStatistical Validity\n\nMessy data can bias results\nWrong conclusions from poorly cleaned data\nNeed to understand messiness to trust analysis\n\nBottom Line: Messy data is the norm, not the exception. Learning to identify, understand, and systematically clean messy data is one of the most practical skills in data analysis. The goal is transforming messy reality into tidy, analyzable datasets while preserving the valuable information buried in the mess!"
  },
  {
    "objectID": "materials-2025/Module 3 - Missing values/01-techniques.html",
    "href": "materials-2025/Module 3 - Missing values/01-techniques.html",
    "title": "01-techniques",
    "section": "",
    "text": "1. Missing Data Methods\n# Instead of just dropping missing values:\ndata_complete &lt;- na.omit(data)  # ??? Loses information\n\n# Use sophisticated imputation:\nlibrary(mice)  # Multiple imputation\nlibrary(VIM)   # Visualization of missing patterns\nlibrary(Hmisc) # Various imputation methods\nApproaches: - Multiple imputation (MICE) - Maximum likelihood estimation\n- Pattern-mixture models - Selection models\n\n\n2. Robust Statistics\nMethods that work well even with outliers/non-normal data:\n# Robust alternatives to standard methods:\nmedian(x)           # vs mean(x)\nmad(x)              # vs sd(x) \nMASS::rlm()         # vs lm() - robust regression\nrobustbase::ltsReg() # least trimmed squares\n\n\n3. Non-parametric Methods\nWhen distributional assumptions fail: - Rank-based tests (Wilcoxon, Kruskal-Wallis) - Bootstrap and permutation tests - Kernel density estimation - Spline regression"
  },
  {
    "objectID": "materials-2025/Module 0 - Setting up/03-hwk-rstudio-git.html",
    "href": "materials-2025/Module 0 - Setting up/03-hwk-rstudio-git.html",
    "title": "Homework 0 Setup B: Connecting RStudio and Git",
    "section": "",
    "text": "Note: This assignment must be submitted in github classroom.\n\n\nConnecting-RStudio-and-Git-Github\n\nClone this repository to your local machine\nOpen RStudio using the project file Connecting-RStudio-and-Git-Github.Rproj\nOpen the file README.Rmd\nMake sure that the following code chunks run successfully\n\n\nLoad Packages …\nVersions\n\n\nInstallations found:\n  &lt; R version 4.5.1 (2025-06-13) &gt;\n  RStudio version: &lt; 2025.5.1.513 &gt;\n  &lt; git version 2.49.0 &gt;\n\nConnection to git\n\n\nRun the code chunk 'gitconnection' at least once successfully.\n✔ Setting active project to \"/Users/hofmann/Documents/Teaching/Stat\n  471/Stat471-Fall-2025/homework-repos/homework-0-setup-B\".\nProject Path:  /Users/hofmann/Documents/Teaching/Stat 471/Stat471-Fall-2025/homework-repos/homework-0-setup-B \nGit repository detected.\nGitHub Remote(s):\n[1] \"origin\"\n\nChecking pull access...\nPull rights: YES \n\nChecking push access...\nPush rights: YES \n\nCreate the README.md file by rendering the README.Rmd file\nCheck the resulting README.md file:\n\nis your version of R (relatively) current? (most current: 4.5.1)\nis your RStudio version from this year?\nis your version of git (relatively) current? (most current: 2.51.0)\n\nIf any of your answers above is ‘no’ install a newer version.\n\nDo you have push and pull access to the Git repository?\n\nIf not, make sure that you have followed all of the steps laid out in chapter 12 of Jenny Bryan’s “Happy Git and GitHub for the useR”\nCommit and push all changed files to Github classroom.\nYour done!"
  },
  {
    "objectID": "materials-2025/Module 0 - Setting up/hwk-1-reproducibility.html",
    "href": "materials-2025/Module 0 - Setting up/hwk-1-reproducibility.html",
    "title": "Homework 1: Reproducibility",
    "section": "",
    "text": "Note: This assignment must be submitted in github classroom.\n\n\nAn example in reproducibility\n\n\nThis repository contains the Nebraskan subset from the 2023 Behavioral Risk Factor Surveillance System (BRFSS). The BRFSS is run annually by the Center for Disease control and prevention (CDC).\nYou can load the data with\nbrfss &lt;- readRDS(\"brfssNE2023.rds\")\nThe dataset contains 12886 observations on 350 variables.\nThe codebook for the full data is available from https://www.cdc.gov/brfss/annual_data/annual_2023.html. A copy of the site is included in the repo in the file USCODE23_LLCP_021924.HTML.\nVariables names starting with X_ in the R data are listed in the codebook without the starting X, i.e. the variable X_AGEG5YR can be found as _AGEG5YR in the codebook.\n\n\nTodo\n\nClone this repository to your local machine and open RStudio using the file reproducibility-brfss.Rproj.\nCreate a quarto document index.qmd. This is the file in which you should include all of your work.\nUse the brfss data described above to find an age distribution of all Nebraskans who participated in the BRFSS survey. Use the variable X_AGEG5YR and show the distribution in a barchart and a table. Make sure to address in a paragraph how you deal with non responses.\n\nIs the age of Nebraskans distributed significantly different from the nationally reported age distribution? (You could run a Chi-square test of homogeneity using chisq.test) Make sure to interpret the results.\nRe-do the analysis in questions 2 and 3 by considering the survey weights X_LLCPWT. Again, interpret the results. How do you explain the differences?\n\n\n\nSubmission\n\nMake sure that your file index.qmd contains all the details needed for me to re-run your analysis.\nEnsure that the file renders without an error.\n\nAdd your file index.qmd to the repository, commit and push."
  },
  {
    "objectID": "materials-2025/Module 2 - Data cleaning/00-outline.html",
    "href": "materials-2025/Module 2 - Data cleaning/00-outline.html",
    "title": "Outline",
    "section": "",
    "text": "Outline\n\nChecking data quality\n\n\nsimple summary statistics"
  },
  {
    "objectID": "materials-2025/Module 2 - Data cleaning/02-outlier-detection-and-mitigation.html",
    "href": "materials-2025/Module 2 - Data cleaning/02-outlier-detection-and-mitigation.html",
    "title": "02-outlier-detection-and-mitigation",
    "section": "",
    "text": "library(VIM)\nVIM::aggr(data)          # Missing data patterns\nVIM::marginplot(data)    # Missing vs observed\n\nlibrary(corrplot)\ncorrplot(cor(data, use = \"pairwise.complete.obs\"))\n\n\n\nlibrary(outliers)\nlibrary(MVN)\n# Multiple methods for identifying problematic observations"
  },
  {
    "objectID": "materials-2025/Module 2 - Data cleaning/02-outlier-detection-and-mitigation.html#diagnostic-tools-for-messy-data",
    "href": "materials-2025/Module 2 - Data cleaning/02-outlier-detection-and-mitigation.html#diagnostic-tools-for-messy-data",
    "title": "02-outlier-detection-and-mitigation",
    "section": "",
    "text": "library(VIM)\nVIM::aggr(data)          # Missing data patterns\nVIM::marginplot(data)    # Missing vs observed\n\nlibrary(corrplot)\ncorrplot(cor(data, use = \"pairwise.complete.obs\"))\n\n\n\nlibrary(outliers)\nlibrary(MVN)\n# Multiple methods for identifying problematic observations"
  },
  {
    "objectID": "materials-2025/Module 0 - Setting up/02-hwk-git-github.html",
    "href": "materials-2025/Module 0 - Setting up/02-hwk-git-github.html",
    "title": "Homework 0 Setup A: Git and Github",
    "section": "",
    "text": "Note: This assignment must be submitted in github classroom."
  },
  {
    "objectID": "materials-2025/Module 0 - Setting up/02-hwk-git-github.html#todo-items",
    "href": "materials-2025/Module 0 - Setting up/02-hwk-git-github.html#todo-items",
    "title": "Homework 0 Setup A: Git and Github",
    "section": "📝 Todo Items",
    "text": "📝 Todo Items\n\nClone this repository to your local machine\nOn your local machine, create a new markdown file in this repository named ‘About_Me.md’.\nIn the file ‘About_Me.md’ include either a or b:\n\n\na short biography/introduction for yourself and use markdown formatting - Markdown Basics provides an overview of different formatting options in markdown. - You must use at least the following formatting elements: header, subheader, bold or italic, bulleted list, and an image.\nprovide a link to your portfolio (hosted on github) that includes all of the above items.\n\n\nCommit your changes to your new file locally and push them back to your github repository. Check on Github to make sure the new file appears."
  },
  {
    "objectID": "materials-2025/Module 0 - Setting up/02-hwk-git-github.html#resources",
    "href": "materials-2025/Module 0 - Setting up/02-hwk-git-github.html#resources",
    "title": "Homework 0 Setup A: Git and Github",
    "section": "📚 Resources",
    "text": "📚 Resources\n\nA short video explaining what GitHub is\nGit and GitHub learning resources\nUnderstanding the GitHub flow\nInteractive Git training materials\nGitHub’s Learning Lab\nEducation community forum\nGitHub community forum"
  },
  {
    "objectID": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#cryptic-names",
    "href": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#cryptic-names",
    "title": "What is “Messy Data”?",
    "section": "Cryptic Names",
    "text": "Cryptic Names\nWhat are the variables? What are the observations?\n\n\n# A tibble: 6 × 4\n  Inst                     AvNumPubs AvNumCits PctCompletion\n  &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 ARIZONA STATE UNIVERSITY      0.9       1.57          31.7\n2 AUBURN UNIVERSITY             0.79      0.64          44.4\n3 BOSTON COLLEGE                0.51      1.03          46.8\n4 BOSTON UNIVERSITY             0.49      2.66          34.2\n5 BRANDEIS UNIVERSITY           0.3       3.03          48.7\n6 BROWN UNIVERSITY              0.84      2.31          54.6"
  },
  {
    "objectID": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#more-cryptic",
    "href": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#more-cryptic",
    "title": "What is “Messy Data”?",
    "section": "More cryptic",
    "text": "More cryptic\nWhat’s in the column names of this data? What are the experimental units? What are the measured variables?\n\n\n# A tibble: 3 × 12\n  id     `WI-6.R1` `WI-6.R2` `WI-6.R4` `WM-6.R1` `WM-6.R2` `WI-12.R1` `WI-12.R2`\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Gene 1      2.18     2.20       4.20     2.63       5.06       4.54       5.53\n2 Gene 2      1.46     0.585      1.86     0.515      2.88       1.36       2.96\n3 Gene 3      2.03     0.870      3.28     0.533      4.63       2.18       5.56\n# ℹ 4 more variables: `WI-12.R4` &lt;dbl&gt;, `WM-12.R1` &lt;dbl&gt;, `WM-12.R2` &lt;dbl&gt;,\n#   `WM-12.R4` &lt;dbl&gt;\n\n\n\nthe experimental design is coded into the variable names, genotype:WI/WM, time:6/12, rep:1/2/4"
  },
  {
    "objectID": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#most",
    "href": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#most",
    "title": "What is “Messy Data”?",
    "section": "Most",
    "text": "Most\nWhat are the variables? What are the records?\n\n\n           V1   V2 V3   V4  V5  V9 V13 V17 V21 V25 V29 V33 V37 V41 V45 V49 V53\n1 ASN00086282 1970  7 TMAX 141 124 113 123 148 149 139 153 123 108 119 112 126\n2 ASN00086282 1970  7 TMIN  80  63  36  57  69  47  84  78  49  42  48  56  51\n3 ASN00086282 1970  7 PRCP   3  30   0   0  36   3   0   0  10  23   3   0   5\n4 ASN00086282 1970  8 TMAX 145 128 150 122 109 112 116 142 166 127 117 127 159\n5 ASN00086282 1970  8 TMIN  50  61  75  67  41  51  48  -7  56  62  47  33  67\n6 ASN00086282 1970  8 PRCP   0  66   0  53  13   3   8   0   0   0   3   5   0\n  V57 V61 V65 V69 V73 V77 V81 V85 V89 V93 V97\n1 112 115 133 134 126 104 143 141 134 117 142\n2  36  44  39  40  58  15  33  51  74  39  66\n3   0   0   0   0   0   8   0  18   0   0   0\n4 143 114  65 113 125 129 147 161 168 178 161\n5  84  11  41  18  50  22  28  74  94  73  88\n6   0  64   3  99  36   8   0   0   0   8  36\n\n\n\nvariables are TMAX, TMIN, PRCP, year, month, day, stationid.\nEach row contains the values for one month!"
  },
  {
    "objectID": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#too_much_info",
    "href": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#too_much_info",
    "title": "What is “Messy Data”?",
    "section": "Too_much_info",
    "text": "Too_much_info\nWhat are the variables? What are the experimental units?\n\n\n# A tibble: 6 × 22\n  iso2   year  m_04 m_514 m_014 m_1524 m_2534 m_3544 m_4554 m_5564  m_65   m_u\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 ZW     2003    NA    NA   133    874   3048   2228    981    367   205    NA\n2 ZW     2004    NA    NA   187    833   2908   2298   1056    366   198    NA\n3 ZW     2005    NA    NA   210    837   2264   1855    762    295   656    NA\n4 ZW     2006    NA    NA   215    736   2391   1939    896    348   199    NA\n5 ZW     2007     6   132   138    500   3693      0    716    292   153    NA\n6 ZW     2008    NA    NA   127    614      0   3316    704    263   185     0\n# ℹ 10 more variables: f_04 &lt;dbl&gt;, f_514 &lt;dbl&gt;, f_014 &lt;dbl&gt;, f_1524 &lt;dbl&gt;,\n#   f_2534 &lt;dbl&gt;, f_3544 &lt;dbl&gt;, f_4554 &lt;dbl&gt;, f_5564 &lt;dbl&gt;, f_65 &lt;dbl&gt;,\n#   f_u &lt;dbl&gt;"
  },
  {
    "objectID": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#tables",
    "href": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#tables",
    "title": "What is “Messy Data”?",
    "section": "Tables",
    "text": "Tables\nWhat are the variables? What are the observations?\n\n\n            religion &lt;$10k $10-20k $20-30k $30-40k\n1           Agnostic    27      34      60      81\n2            Atheist    12      27      37      52\n3           Buddhist    27      21      30      34\n4           Catholic   418     617     732     670\n5 Don’t know/refused    15      14      15      11"
  },
  {
    "objectID": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#gross-on-repeat",
    "href": "materials-2025/Module 1 - Tidy Forms of Data/01-tidy-data.html#gross-on-repeat",
    "title": "What is “Messy Data”?",
    "section": "Gross on repeat",
    "text": "Gross on repeat\n10 week sensory experiment, 12 individuals assessed taste of french fries on several scales (how potato-y, buttery, grassy, rancid, paint-y do they taste?), fried in one of 3 different oils, replicated twice.\nFirst few rows:\n\n\n# A tibble: 4 × 9\n  time  treatment subject   rep potato buttery grassy rancid painty\n  &lt;fct&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 1     1         3           1    2.9     0      0      0      5.5\n2 1     1         3           2   14       0      0      1.1    0  \n3 1     1         10          1   11       6.4    0      0      0  \n4 1     1         10          2    9.9     5.9    2.9    2.2    0  \n\n\nWhat is the experimental unit? What are the factors of the experiment? What was measured? What do you want to know?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Stat 471 - Analysis of Messy Data",
    "section": "",
    "text": "Fall 2025\nTR 3:30 - 4:45 pm, Canvas\nOffice Hours: by appointment\nInstructor: Heike Hofmann, hhofmann4 at unl dot edu\n\n\n\nCourse description\n\nAnalysis of complex, real-world data sets. Analysis techniques will vary depending on interest and availability of data sets.\n\nNot all data lives in nice, clean spreadsheets, not all data fits in a computer’s main memory. As statisticians we cannot always rely on other people and sciences to get the data into formats that we can deal with: we will discuss aspects of statistical computing as they are relevant for data analysis. Elements of literate programming help us with making our workflow transparent and analyses reproducible. We will discuss communication of results in form of web sites and interactive web applications.\n\n\nLearn how to …\n\ncompute with data to check the quality,\nimpute missing values, wrangle data formats, and join data sources.\nwrite efficient and reproducible code so others are able to replicate the analysis.\npull data together to solve a contemporary problem.\nuse LLM bots to assess their helpfulness in different situations\npublish reports on the web\n\n\n\nMore Info …\nThe course organization on GitHub: https://github.com/stat471-at-UNL/stat471-at-UNL.github.io\nRepo that creates this website: https://github.com/stat471-at-UNL/materials-2025"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Project: Screencast",
    "section": "",
    "text": "Project Description\nFor your final project (which will take the place of the final exam), you will be recording a screencast in the style of David Robinson’s TidyTuesday screencasts.\nYou can find time-stamped, catalogued versions of some of David Robinson’s screencasts here.\nRequirements:\n\nYour screencast should be approximately 45 minutes long.\nYour screencast should show your analysis of a TidyTuesday dataset from 2023\nYou should showcase at least 4 different techniques you’ve learned in Stat 251. Some examples include:\n\ndata cleaning (dplyr) verbs\nreshaping data (tidyr)\nworking with dates and times (lubridate)\nworking with strings (stringr)\nwriting functions to modularize your code\nvisualizing your data effectively\n\n\nUnlike David Robinson’s screencasts, you will write a rough pseudocode “script” before you start recording. This will give you a rough outline of how to do the analysis and what things you intend to cover.\nYour goal is to help a future Stat 251 student understand some of the topics covered in this class. So while David Robinson and others who record their screencasts live might not fully explain what he’s doing, you should take the time to explain each technique you decide to use in a way that will help someone else understand.\nThere will be three deliverables for this project:\n\nPlan your dataset and topics\nPseudocode script uploaded to github repository\nScreencast + github repository\n\nScreencast uploaded to YouTube/YuJa\nApproximate time index provided for each of the 4 techniques you’re demonstrating (examples)\nCode uploaded to github repository\n\n\nIn lieu of the final exam, you will peer review two classmates’ screencasts."
  },
  {
    "objectID": "project/Dataset-Topics.html",
    "href": "project/Dataset-Topics.html",
    "title": "Project Dataset and Topics",
    "section": "",
    "text": "Link to dataset\nThings you plan to investigate using this dataset:\n\nThing 1\nThing 2\nThing 3\n\nStat 251 topics you plan to cover during the analysis:\n\nTopic 1\nTopic 2\nTopic 3\nTopic 4"
  }
]